{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oneTBB Loop Partitioners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sections\n",
    "- [The partitioners available in oneTBB](#The-partitioners-available-in-oneTBB)\n",
    "- _Code_: [Partitioners and grainsize](#Partitioners-and-grainsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "* Learn to use partitioners to change the way that oneTBB divides TBB Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The partitioners available in oneTBB\n",
    "\n",
    "There are several partitioners provided in oneTBB that can be used with the loop algorithms: \n",
    "`parallel_for`, `parallel_reduce` and `parallel_scan`.  The table below summarizes their\n",
    "behaviors.\n",
    "\n",
    "![Partitioner Table](img/partitioners.png)\n",
    "\n",
    "In this module, we will use different partitioners and grainsizes and see their effect\n",
    "on the distribution of tasks to threads and the size of tasks created by a simple use of `tbb::parallel_for`.\n",
    "In real applications, we need to consider both\n",
    "application characteristics and the platform characteristics\n",
    "to select the best partitioner for our problem.\n",
    "\n",
    "`auto_partitioner` is the default for TBB loop algorithms and is typically a good choice.\n",
    "It tries to create chunks that are small enough to allow for dynamic load balancing, without\n",
    "creating very small tasks that lead to excessive scheduling overheads.\n",
    "\n",
    "A `simple_partitioner` is useful when you want to carefully control grainsizes and do not \n",
    "want TBB to automatically determine the size of chunks distributed to threads. This can be\n",
    "useful, for example, when implementing cache-oblivious algorithms, where it is important to\n",
    "divide the iteration space into small enough pieces to benefit from cache-obliviousness.\n",
    "\n",
    "`affinity_partitioner` is useful when you can benefit from repeating the same distribution of\n",
    "tasks to threads on multiple invocations of loop nests. It determines chunk sizes using an\n",
    "algorithm similar to `auto_partitioner` but stores the pattern and attempts to recreate it on\n",
    "future executions.\n",
    "\n",
    "Finally, `static_partitioner` has the lowest overheads since, as its name implies, it doesn't\n",
    "do dynamic balancing of the load. When we have a well balanced workload running on a unloaded\n",
    "machine, a static partitioning can provide excellent performance. However if the workload is\n",
    "imbalanced or some cores are more loaded than others, we lose the benefits of dynamic load\n",
    "balancing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out partitioners\n",
    "\n",
    "In this section, we will execute a very simple example that runs a `tbb::parallel_for` that\n",
    "spins for roughly 100 nanoseconds for each loop iteration. Since all of the iterations spin\n",
    "for roughly the same amount of time, there is no load imbalance among the iterations. But our\n",
    "example records the assignment of iterations to threads and we will visualize this assignment\n",
    "using a python script.  The output will also state how many loop body tasks were created and\n",
    "how long the loop took to execute.\n",
    "\n",
    "The test loop, found in common/partitioner_test.cpp, is reproduced below:\n",
    "\n",
    "```cpp\n",
    "std::atomic<int> num_body_executions = 0;\n",
    "\n",
    "template<typename Partitioner>\n",
    "static auto run_test(const std::string &partitioner_name, int gs = 1) {\n",
    "  auto t0 = std::chrono::high_resolution_clock::now();\n",
    "  tbb::parallel_for(tbb::blocked_range<int>(0, \n",
    "                                            std::thread::hardware_concurrency() * 1000, \n",
    "                                            gs),\n",
    "    [v](const tbb::blocked_range<int> &b) {\n",
    "      const int time_per_iteration = 100; // 100 ns\n",
    "      ++num_body_executions;\n",
    "      for (int i = b.begin(); i < b.end(); ++i) {\n",
    "        auto t0 = std::chrono::high_resolution_clock::now();\n",
    "        while ((std::chrono::high_resolution_clock::now() - t0).count() < time_per_iteration);\n",
    "        v[i] = tbb::this_task_arena::current_thread_index();\n",
    "      }\n",
    "    }, Partitioner{}\n",
    "  );\n",
    "  double execution_time = 1e-9*(std::chrono::high_resolution_clock::now() - t0).count();\n",
    "  return std::make_pair( execution_time, number_of_body_executions );\n",
    "}\n",
    "```\n",
    "\n",
    "In the code above, Partitioner is the partitioner type passed as a template argument to run_test \n",
    "and `gs` is an optional grainsize. The test will execute the parallel loop using \n",
    "`std::thread::hardware_concurrency() * 1000` iterations. Each iteration will spin for about 100 ns.\n",
    "The output will be written to a csv file so that it can be viewed as a 2D graph showing which\n",
    "threads executed which iterations. The threads will appear as different colors.\n",
    "\n",
    "Perform the following steps to complete this exercise:\n",
    "1. Inspect the code cell below, then click run ▶ to save the code to a file\n",
    "2. Run ▶ the cell in the __Build and Run__ section below the code snippet to compile, execute the code and generate the output graph.  Not the distribution of colors, the number of body tasks executed and the execution time.\n",
    "3. Modify the grainsize argument, trying values such as 10, 100 and 1000. Then re-run the cell in the __Build and Run__ section to generate a new graph and results.\n",
    "4. Pass a grainsize of 1 but use different partitioners, such as `auto_partitioner` and `static_partitioner`. After each change, re-run the cell in the __Build and Run__ section to generate a new graph and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/partitioner.cpp\n",
    "//==============================================================\n",
    "// Copyright (c) 2020 Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: Apache-2.0\n",
    "// =============================================================\n",
    "\n",
    "#include \"../common/partitioner_test.h\"\n",
    "#include <iostream>\n",
    "\n",
    "int main() {\n",
    "  // STEP 3: Try different grainsize values, maybe 10, 100 and 1000\n",
    "  // STEP 4: Pass a grainsize of 1, but change the partitioner type to auto_partitioner or static_partitioner\n",
    "  auto r = run_test<tbb::simple_partitioner>(/* title in chart */ \"simple_partitioner\", /* grainsize */ 1);\n",
    "  std::cout << \"Wallclock time == \" << r.first << \"\\n\"\n",
    "            << \"Number of body executions == \" << r.second << \"\\n\";\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 755 q; chmod 755 ./scripts/run_partitioner.sh; if [ -x \"$(command -v qsub)\" ]; then ./q scripts/run_partitioner.sh; else ./scripts/run_partitioner.sh; fi\n",
    "%run common/plot_tids.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
